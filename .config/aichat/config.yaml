# see https://github.com/sigoden/aichat/blob/main/config.example.yaml

model: llama-cpp:Qwen/Qwen3-14B
stream: true
use_tools: all
clients:
- type: openai-compatible
  name: llama-cpp
  api_base: http://mahmooz2:5000/v1
  models:
  - name: Qwen/Qwen3-14B